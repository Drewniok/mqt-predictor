{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from mqt.predictor import rl, ml\n",
    "df = pd.read_csv(ml.helper.get_path_results(), sep=',')\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 30\n",
    "\n",
    "apply_normalization = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd42294",
   "metadata": {},
   "source": [
    "# 2x2 Matrix With Mean Results and Optimization Criterion Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a887a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[df[\"MQTPredictor_expected_fidelity_expected_fidelity\"]>=0]\n",
    "tmp_df = tmp_df[tmp_df[\"MQTPredictor_critical_depth_expected_fidelity\"]>=0]\n",
    "MQT_expected_fidelity = [tmp_df[\"MQTPredictor_expected_fidelity_expected_fidelity\"].mean(),  tmp_df[\"MQTPredictor_expected_fidelity_critical_depth\"].mean()]\n",
    "MQT_critical_depth = [tmp_df[\"MQTPredictor_critical_depth_expected_fidelity\"].mean(), tmp_df[\"MQTPredictor_critical_depth_critical_depth\"].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d299e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(MQT_expected_fidelity,2))\n",
    "print(np.round(MQT_critical_depth,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf93d18b-b61a-47ae-988c-590e25e2f203",
   "metadata": {},
   "source": [
    "## Top 3 Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649aff4-7fb8-457f-9ec8-c1cd97bbc4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "    plt.xlim(bins[0], bins[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb6e96-22c3-4739-b480-75d7b9a42785",
   "metadata": {},
   "source": [
    "## Calcualte Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d28b11-cf2b-4286-a09a-05098b0cfd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median(row, column_name):\n",
    "    columns = [col for col in row.index if col.endswith(column_name) and not \"MQT\" in col]\n",
    "    values = [value for col, value in row[columns].items() if value != -1]\n",
    "    return np.median(values) if values else None\n",
    "\n",
    "df['expected_expected_fidelity_median'] = df.apply(calculate_median, column_name=\"_expected_fidelity\",axis=1)\n",
    "df['critical_depth_median'] = df.apply(calculate_median, column_name=\"_critical_depth\",axis=1)\n",
    "df['expected_expected_fidelity_min_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_expected_fidelity') and 'MQT' not in col]].replace(-1, np.nan).min(skipna=True), axis=1)\n",
    "df['expected_expected_fidelity_max_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_expected_fidelity') and 'MQT' not in col]].max(), axis=1)\n",
    "df['critical_depth_min_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_critical_depth') and 'MQT' not in col]].replace(-1, np.nan).min(skipna=True), axis=1)\n",
    "df['critical_depth_max_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_critical_depth') and 'MQT' not in col]].max(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15623d11-8024-4d65-ac23-b468af76ab70",
   "metadata": {},
   "source": [
    "## Optionally: Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86906f27-0c80-4f63-a8fe-c1310a38e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_normalization:\n",
    "    divider_column_name = 'expected_expected_fidelity_max_other'\n",
    "    \n",
    "    # Get the list of column names ending with \"_expected_fidelity\"\n",
    "    columns_to_divide = [col for col in df.columns if col.endswith(\"_expected_fidelity\") or col in ['expected_expected_fidelity_min_other', 'exptected_expected_fidelity_max_other', 'exptected_expected_fidelity_median' ]]\n",
    "    \n",
    "    # Iterate through each column and perform the division\n",
    "    for col_name in columns_to_divide:\n",
    "        df[col_name] = df[col_name].divide(df[divider_column_name])\n",
    "    \n",
    "    divider_column_name = 'critical_depth_max_other'\n",
    "    \n",
    "    # Get the list of column names ending with \"_expected_fidelity\"\n",
    "    columns_to_divide = [col for col in df.columns if col.endswith(\"_critical_depth\") or col in ['critical_depth_min_other', 'critical_depth_max_other',  'critical_depth_median' ]]\n",
    "    \n",
    "    # Iterate through each column and perform the division\n",
    "    for col_name in columns_to_divide:\n",
    "        df[col_name] = df[col_name].divide(df[divider_column_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686119db-4ea4-4d61-9fd4-50d06131301c",
   "metadata": {},
   "source": [
    "# Expected Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a7376-c5e1-483d-ba5d-aa476ed55da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ml.Predictor()\n",
    "\n",
    "training_data = predictor.get_prepared_training_data(figure_of_merit=\"expected_fidelity\", save_non_zero_indices=True)\n",
    "indices_test = training_data.indices_test\n",
    "names_list = training_data.names_list\n",
    "\n",
    "test_benchmarks_expected_fidelity = [names_list[index_test] for index_test in indices_test]\n",
    "df_filtered_expected_fidelity = df[df[\"file_path\"].isin(test_benchmarks_expected_fidelity)]\n",
    "df_filtered_expected_fidelity = df_filtered_expected_fidelity[df_filtered_expected_fidelity[\"MQTPredictor_expected_fidelity_expected_fidelity\"]>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9f7d1-f565-4d14-ad75-b0e8bb2820fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fid Improvement: \", df_filtered_expected_fidelity.loc[df['MQTPredictor_expected_fidelity_expected_fidelity'] != np.inf, 'MQTPredictor_expected_fidelity_expected_fidelity'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83daed-b560-405f-867d-e2b568773b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered_expected_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3ad43-c57f-45fe-b0bc-e0476e504178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_expected_fidelity['MQTPredictor_expected_fidelity_expected_fidelity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cea6af-5e3d-4350-9e81-004a96cf697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kind = \"line\"\n",
    "df_filtered_and_sorted_expected_fidelity = df_filtered_expected_fidelity.sort_values(by=['MQTPredictor_expected_fidelity_expected_fidelity'])\n",
    "ax = df_filtered_and_sorted_expected_fidelity.plot(x=\"file_path\", y=\"expected_expected_fidelity_max_other\", label=\"Best\", rot=90, kind=plot_kind, color=\"green\", figsize=(30,10))\n",
    "df_filtered_and_sorted_expected_fidelity.plot(x=\"file_path\", y=\"MQTPredictor_expected_fidelity_expected_fidelity\", label=\"MQT Predictor\", kind=plot_kind, rot=90, ax=ax, color=\"blue\")\n",
    "df_filtered_and_sorted_expected_fidelity.plot(x=\"file_path\", y=\"expected_expected_fidelity_median\", kind=plot_kind, rot=90, ax=ax, color=\"orange\", label=\"Median\")\n",
    "df_filtered_and_sorted_expected_fidelity.plot(x=\"file_path\", y=\"expected_expected_fidelity_min_other\", label=\"Worst\", rot=90, kind=plot_kind, ax=ax, color=\"red\")\n",
    "\n",
    "if plot_kind == \"line\":\n",
    "    plt.xticks(range(len(df_filtered_and_sorted_expected_fidelity.file_path)), df_filtered_and_sorted_expected_fidelity.file_path)\n",
    "\n",
    "plt.xticks(\n",
    "    list(range(0, len(df_filtered_and_sorted_expected_fidelity.file_path), 1)),\n",
    "    [ \"\" for i in range(0, len(df_filtered_and_sorted_expected_fidelity.file_path), 1)],\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Benchmarks\")\n",
    "plt.ylabel(\"Expected expected_fidelity\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1,0,2,3]\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order]) \n",
    "\n",
    "plt.savefig(\"results/expected_fidelity_plot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded0ef5-8852-4375-9eec-4dfd6779d5bc",
   "metadata": {},
   "source": [
    "## Top 3 expected_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a114c67-fd76-4c92-b320-fdb6e686914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_and_sorted_expected_fidelity['Rank_MQT_expected_fidelity'] = df_filtered_and_sorted_expected_fidelity.apply(lambda row: sum(1 for col in df_filtered_and_sorted_expected_fidelity.columns if col.endswith('_expected_fidelity') and not \"MQT\" in col and row['MQTPredictor_expected_fidelity_expected_fidelity'] >=row[col]), axis=1)\n",
    "df_filtered_and_sorted_expected_fidelity['Rank_MQT_expected_fidelity'] = len([col for col in df_filtered_and_sorted_expected_fidelity.columns if col.endswith('_expected_fidelity') and not \"MQT\" in col]) - df_filtered_and_sorted_expected_fidelity.Rank_MQT_expected_fidelity\n",
    "plt.hist(df_filtered_and_sorted_expected_fidelity.Rank_MQT_expected_fidelity.values, bins=range(0,15,1), align=\"left\", weights=np.ones(len(df_filtered_and_sorted_expected_fidelity)) / len(df_filtered_and_sorted_expected_fidelity))\n",
    "plt.xticks(range(0,14,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868e984-55f7-4aa5-a5e7-1c23e536d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered_and_sorted_expected_fidelity[df_filtered_and_sorted_expected_fidelity['Rank_MQT_expected_fidelity']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af212b6-a835-4594-b284-ae005e2f498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered_and_sorted_expected_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2c7fe-cf66-481b-8ca4-84811372d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_top3 = 0\n",
    "for index, row in df_filtered_and_sorted_expected_fidelity.iterrows():\n",
    "    if row['Rank_MQT_expected_fidelity'] in [0, 1, 2]:\n",
    "        count_top3 += 1\n",
    "        \n",
    "print(\"Percentage of Top-3:\", count_top3/len(df_filtered_and_sorted_expected_fidelity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb822e-f064-4678-9d2e-df6a8b505f92",
   "metadata": {},
   "source": [
    "# Critical Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c66682-f7b6-4b6b-9ec8-35ea240d32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ml.Predictor()\n",
    "training_data = predictor.get_prepared_training_data(figure_of_merit=\"critical_depth\", save_non_zero_indices=True)\n",
    "indices_test = training_data.indices_test\n",
    "names_list = training_data.names_list\n",
    "\n",
    "test_benchmarks_critical_depth = [names_list[index_test] for index_test in indices_test]\n",
    "df_filtered_critical_depth = df[df[\"file_path\"].isin(test_benchmarks_critical_depth)]\n",
    "df_filtered_critical_depth = df_filtered_critical_depth[df_filtered_critical_depth[\"MQTPredictor_critical_depth_critical_depth\"]>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5c6ea-e092-4225-b356-9e1c9b8e40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Crit. Dep. Improvement: \", df_filtered_critical_depth.loc[df['MQTPredictor_critical_depth_critical_depth'] != np.inf, 'MQTPredictor_critical_depth_critical_depth'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86663c8-ba0c-4e5f-a810-c6cab4744487",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered_critical_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566bcf3-397e-44ec-88e6-beb159e1b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kind = \"line\"\n",
    "df_filtered_and_sorted_critical_depth = df_filtered_critical_depth.sort_values(by=['MQTPredictor_critical_depth_critical_depth'])\n",
    "ax = df_filtered_and_sorted_critical_depth.plot(x=\"file_path\", y=\"critical_depth_max_other\", label=\"Best\", rot=90, kind=plot_kind, color=\"green\", figsize=(30,10))\n",
    "df_filtered_and_sorted_critical_depth.plot(x=\"file_path\", y=\"MQTPredictor_critical_depth_critical_depth\", kind=plot_kind, rot=90, ax=ax, color=\"blue\", label=\"MQT Predictor\")\n",
    "df_filtered_and_sorted_critical_depth.plot(x=\"file_path\", y=\"critical_depth_median\", kind=plot_kind, rot=90, ax=ax, color=\"orange\", label=\"Median\")\n",
    "df_filtered_and_sorted_critical_depth.plot(x=\"file_path\", y=\"critical_depth_min_other\", label=\"Worst\", rot=90, kind=plot_kind, ax=ax, color=\"red\")\n",
    "\n",
    "\n",
    "if plot_kind == \"line\":\n",
    "    plt.xticks(range(len(df_filtered_and_sorted_critical_depth.file_path)), df_filtered_and_sorted_critical_depth.file_path);\n",
    "\n",
    "\n",
    "plt.xticks(\n",
    "    list(range(0, len(df_filtered_and_sorted_critical_depth.file_path), 1)),\n",
    "    [\"\" for i in range(0, len(df_filtered_and_sorted_critical_depth), 1)],\n",
    "    fontsize=18,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Benchmarks\")\n",
    "plt.ylabel(\"Critical Depth\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1,0,2,3]\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order]) \n",
    "\n",
    "plt.savefig(\"results/critical_depth_plot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941a75a-abb0-45eb-b850-8c948b411f37",
   "metadata": {},
   "source": [
    "## Top 3 Critical Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d74e70-8ec1-4ea6-a770-4726a6a04d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_and_sorted_critical_depth['Rank_MQT_critical_depth'] = df_filtered_and_sorted_critical_depth.apply(lambda row: sum(1 for col in df_filtered_and_sorted_critical_depth.columns if col.endswith('_critical_depth') and not \"MQT\" in col and row['MQTPredictor_critical_depth_critical_depth'] >= row[col]), axis=1)\n",
    "df_filtered_and_sorted_critical_depth['Rank_MQT_critical_depth'] = len([col for col in df_filtered_and_sorted_critical_depth.columns if col.endswith('_critical_depth') and not \"MQT\" in col]) - df_filtered_and_sorted_critical_depth.Rank_MQT_critical_depth\n",
    "plt.hist(df_filtered_and_sorted_critical_depth.Rank_MQT_critical_depth.values, bins=range(0,15,1), align=\"left\", weights=np.ones(len(df_filtered_and_sorted_critical_depth)) / len(df_filtered_and_sorted_critical_depth))\n",
    "plt.xticks(range(0,14,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa9861-4e45-4b1d-86bb-22cfd6b28761",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered_and_sorted_critical_depth[df_filtered_and_sorted_critical_depth['Rank_MQT_critical_depth']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6464b-823a-4169-b5ab-03c11f7966cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered_and_sorted_critical_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370efe4-7039-4563-8f3a-62e3f6eda620",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_top3 = 0\n",
    "for index, row in df_filtered_and_sorted_critical_depth.iterrows():\n",
    "    if row['Rank_MQT_critical_depth'] in [0, 1, 2]:\n",
    "        count_top3 += 1\n",
    "\n",
    "# Print the total count\n",
    "print(\"Percentage of Top-3:\", count_top3/len(df_filtered_and_sorted_critical_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ae124-6ca5-4d7d-87e5-eb277b813b68",
   "metadata": {},
   "source": [
    "# GHZ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e19ce9-82c3-40fe-83ab-5e5310596f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ml.helper.get_path_results(ghz_results=True), sep=',')\n",
    "df = df[df.num_qubits<32]\n",
    "plt.rcParams[\"font.size\"] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357af6f-5afc-4d12-ba5e-2a7f0a1f7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expected_fidelity_median'] = df.apply(calculate_median, column_name=\"_expected_fidelity\",axis=1)\n",
    "df['critical_depth_median'] = df.apply(calculate_median, column_name=\"_critical_depth\",axis=1)\n",
    "df['expected_fidelity_min_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_expected_fidelity') and 'MQT' not in col]].replace(-1, np.nan).min(skipna=True), axis=1)\n",
    "df['expected_fidelity_max_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_expected_fidelity') and 'MQT' not in col]].max(), axis=1)\n",
    "df['critical_depth_min_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_critical_depth') and 'MQT' not in col]].replace(-1, np.nan).min(skipna=True), axis=1)\n",
    "df['critical_depth_max_other'] = df.apply(lambda row: row[[col for col in row.index if col.endswith('_critical_depth') and 'MQT' not in col]].max(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee34f6-32cb-4176-b557-962f7605ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kind = \"line\"\n",
    "df = df.sort_values(by=['num_qubits'])\n",
    "ax = df.plot(x=\"file_path\", y=\"expected_fidelity_max_other\", label=\"Best\", rot=90, kind=plot_kind, color=\"green\", figsize=(20,10))\n",
    "df.plot(x=\"file_path\", y=\"MQTPredictor_expected_fidelity_expected_fidelity\", label=\"MQT Predictor\", kind=plot_kind, rot=90, ax=ax, color=\"blue\")\n",
    "df.plot(x=\"file_path\", y=\"expected_fidelity_median\", kind=plot_kind, rot=90, ax=ax, color=\"orange\", label=\"Median\")\n",
    "df.plot(x=\"file_path\", y=\"expected_fidelity_min_other\", label=\"Worst\", rot=90, kind=plot_kind, ax=ax, color=\"red\")\n",
    "\n",
    "if plot_kind == \"line\":\n",
    "    plt.xticks(range(len(df.file_path)), df.file_path)\n",
    "\n",
    "plt.xticks(\n",
    "    list(range(0, len(df), 1)),\n",
    "    [df.iloc[i].num_qubits if i % 4 == 1 else \"\" for i in range(len(df))],\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Number of Qubits\")\n",
    "plt.ylabel(\"Expected Fidelity\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1,0,2,3]\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order]) \n",
    "\n",
    "\n",
    "plt.savefig(\"results/expected_fidelity_ghz_plot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1454e-dedf-421d-a347-badb32ccbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kind = \"line\"\n",
    "df = df.sort_values(by=['num_qubits'])\n",
    "ax = df.plot(x=\"file_path\", y=\"critical_depth_max_other\", label=\"Best\", rot=90, kind=plot_kind, color=\"green\", figsize=(20,10))\n",
    "df.plot(x=\"file_path\", y=\"MQTPredictor_critical_depth_critical_depth\", kind=plot_kind, rot=90, ax=ax, color=\"blue\", label=\"MQT Predictor\")\n",
    "df.plot(x=\"file_path\", y=\"critical_depth_median\", kind=plot_kind, rot=90, ax=ax, color=\"orange\", label=\"Median\")\n",
    "\n",
    "if plot_kind == \"line\":\n",
    "    plt.xticks(range(len(df.file_path)), df.file_path);\n",
    "\n",
    "plt.xticks(\n",
    "    list(range(0, len(df), 1)),\n",
    "    [df.iloc[i].num_qubits if i % 4 == 1 else \"\" for i in range(len(df))],\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Number of Qubits\")\n",
    "plt.ylabel(\"Critical Depth\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1,0,2]\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order]) \n",
    "\n",
    "plt.savefig(\"results/critical_depth_ghz_plot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e66ba2c591673",
   "metadata": {},
   "source": [
    "# Evaluation Journal Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fafd3d-47ee-4dd3-b74c-99c7e2cb75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ml.helper.get_path_results(), sep=',')\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "#plt.rcParams[\"lines.markersize\"] = 2\n",
    "\n",
    "device = \"ibm_washington\"\n",
    "device_index = rl.helper.get_device_index_of_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457fe83f0d56a31",
   "metadata": {},
   "source": [
    "## Data Preparation Expected Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9299af0-c878-43ba-b9b2-b1ae00f8d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_expected_fidelity = predictor.get_prepared_training_data(figure_of_merit=\"expected_fidelity\", save_non_zero_indices=True)\n",
    "indices_test_expected_fidelity = training_data_expected_fidelity.indices_test\n",
    "names_list_expected_fidelity = training_data_expected_fidelity.names_list\n",
    "names_test_expected_fidelity = [names_list_expected_fidelity[index_test] for index_test in indices_test_expected_fidelity]\n",
    "scores_test_expected_fidelity = [training_data_expected_fidelity.scores_list[index_test] for index_test in indices_test_expected_fidelity]\n",
    "df_expected_fidelity = df[df[\"file_path\"].isin(names_test_expected_fidelity)]\n",
    "df_expected_fidelity[\"RL_\" + device + \"_expected_fidelity\"] = df_expected_fidelity.apply(\n",
    "    lambda row: max(\n",
    "        scores_test_expected_fidelity[\n",
    "            names_test_expected_fidelity.index(row[\"file_path\"])\n",
    "        ][device_index], \n",
    "        0), \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a1826d40b3117",
   "metadata": {},
   "source": [
    "## Data Preparation Critical Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178db5f754fbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_critical_depth = predictor.get_prepared_training_data(figure_of_merit=\"critical_depth\", save_non_zero_indices=True)\n",
    "indices_test_critical_depth = training_data_critical_depth.indices_test\n",
    "names_list_critical_depth = training_data_critical_depth.names_list\n",
    "names_test_critical_depth = [names_list_critical_depth[index_test] for index_test in indices_test_critical_depth]\n",
    "scores_test_critical_depth = [training_data_critical_depth.scores_list[index_test] for index_test in indices_test_critical_depth]\n",
    "df_critical_depth = df[df[\"file_path\"].isin(names_test_critical_depth)]\n",
    "df_critical_depth[\"RL_\" + device + \"_critical_depth\"] = df_critical_depth.apply(\n",
    "    lambda row: max(\n",
    "        scores_test_critical_depth[\n",
    "            names_test_critical_depth.index(row[\"file_path\"])]\n",
    "        [device_index], \n",
    "        0), \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d673422529d0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "qasm_path = ml.helper.get_path_training_circuits()\n",
    "\n",
    "for fom in [\"expected_fidelity\", \"critical_depth\"]:\n",
    "    if fom == \"expected_fidelity\":\n",
    "        df = df_expected_fidelity\n",
    "    else:\n",
    "        df = df_critical_depth\n",
    "    df[f\"predicted_device_{fom}\"] = df.apply(\n",
    "    lambda row: ml.helper.predict_device_for_figure_of_merit(\n",
    "        QuantumCircuit.from_qasm_file(\n",
    "            qasm_path/(row[\"file_path\"]+\".qasm\")), \n",
    "        figure_of_merit=fom), \n",
    "    axis=1)\n",
    "    df[\"num_qubits_interval\"] = pd.cut(df[\"num_qubits\"], [0, 8, 11, 25, 27, 32, 80, 127], labels=[\"1-8\", \"9-11\", \"12-25\", \"26-27\",\"28-32\", \"33-80\", \"81-127\"])\n",
    "    ax = df.groupby([\"num_qubits_interval\", f\"predicted_device_{fom}\"]).size().unstack().fillna(0).plot(kind='bar', stacked=True, color=[\"#fde725\", \"#90d743\", \"#35b779\", \"#21918c\", \"#31688e\", \"#443983\", \"#440154\"])\n",
    "    ax.figure.savefig(f\"results/predicted_devices_{fom}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f850985b121281",
   "metadata": {},
   "source": [
    "# Eval ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f672a48b51f2cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fom in [\"expected_fidelity\", \"critical_depth\"]:\n",
    "    if fom == \"expected_fidelity\":\n",
    "        df = df_expected_fidelity\n",
    "    else:\n",
    "        df = df_critical_depth\n",
    "    \n",
    "    df = df.sort_values(by=[f'MQTPredictor_{fom}_{fom}'])\n",
    "    df = df.sort_values(by=[f\"RL_\" + device + f\"_{fom}\"])\n",
    "    \n",
    "    plt.scatter(range(len(df)), df[\"qiskit_\" + device + f\"_{fom}\"], label=\"Qiskit\", color=\"#fde725\", marker=\"x\")\n",
    "    plt.scatter(range(len(df)), df[\"tket_\" + device + f\"_{fom}\"], label=\"TKET\", color=\"#35b779\", marker=\".\")\n",
    "    plt.scatter(range(len(df)), df[\"RL_\" + device + f\"_{fom}\"], label=\"MQT_Predictor only RL\", color=\"#440154\", marker=\"o\")\n",
    "    plt.scatter(range(len(df)), df[f'MQTPredictor_{fom}_{fom}'], label=\"MQT_Predictor\", color=\"#31688e\", marker=\"+\")\n",
    "    \n",
    "    plt.title(f\"Difference between the {fom} for MQT Predictor on the predicted device vs. the all baselines for the largest devices\")\n",
    "    plt.legend()\n",
    "    plt.savefig(fname=f\"results/ml_{fom}_comparison.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501f3b07ed43414",
   "metadata": {},
   "source": [
    "## Eval RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9936f9c8dba9fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fom in [\"expected_fidelity\", \"critical_depth\"]:\n",
    "    if fom == \"expected_fidelity\":\n",
    "        df = df_expected_fidelity\n",
    "    else:\n",
    "        df = df_critical_depth  \n",
    "    df = df.sort_values(by=[f'MQTPredictor_{fom}_{fom}'])\n",
    "\n",
    "    MQT = []\n",
    "    qiskit = []\n",
    "    tket = []\n",
    "\n",
    "    \n",
    "    for i, row in enumerate(df.iterrows()):\n",
    "        MQT.append(row[1][[f'MQTPredictor_{fom}_{fom}']])\n",
    "        qiskit.append(row[1][\"qiskit_\" + row[1][f\"predicted_device_{fom}\"] + f\"_{fom}\"])\n",
    "        tket.append(row[1][\"tket_\" + row[1][f\"predicted_device_{fom}\"] + f\"_{fom}\"])\n",
    "    plt.scatter(range(len(df)), qiskit, label=\"Qiskit\", color=\"#fde725\", marker=\"x\")\n",
    "    plt.scatter(range(len(df)), tket, label=\"TKET\", color=\"#35b779\", marker=\".\")\n",
    "    plt.scatter(range(len(df)), MQT, label=\"MQT Predictor\", color=\"#440154\", marker=\"+\")\n",
    "    plt.title(f\"Comparison of the {fom} for the predicted device\")\n",
    "    plt.legend()\n",
    "    plt.savefig(fname=f\"results/rl_{fom}_comparison.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99b2551bc7a03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6fda1444f4dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
